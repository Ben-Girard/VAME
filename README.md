![VAME](https://github.com/LINCellularNeuroscience/VAME/blob/master/Images/VAME_Logo.png)
![workflow](https://github.com/LINCellularNeuroscience/VAME/blob/master/Images/workflow.png)

# VAME in a Nutshell
VAME is a framework to cluster behavioral signals obtained from pose-estimation tools. It is a [PyTorch](https://pytorch.org/) based deep learning framework which leverages the power of recurrent neural networks (RNN) to model sequential data. In order to learn the underlying complex data distribution we use the RNN in a [variational autoencoder](https://github.com/LINCellularNeuroscience/VAME/wiki/Introduction-to-variational-autoencoder) setting to extract the latent state of the animal in every time step. 

The workflow of VAME consists of 5 steps and we explain them in detail [here](https://github.com/LINCellularNeuroscience/VAME/wiki/VAME-workflow).

## Installation of VAME

## Getting Started

## News

### Authors and Code Contributors
VAME was developed by Kevin Luxem and Pavol Bauer

### References
If you use this code or data please cite

### License
